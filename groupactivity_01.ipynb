{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c7080b",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1><b>CSC173: Group Activity 1<b></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b4578",
   "metadata": {},
   "source": [
    "<center><i>Members: Febe Belvis, Kervin Paalisbo, Joshua Radz Adlaon</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa39f6a",
   "metadata": {},
   "source": [
    "This notebook documents this group's Activity 1, where the goal is to implement a neural network from scratch (without using machine learning libraries such as TensorFlow or PyTorch). The neural network will be trained and evaluated on the Breast Cancer dataset from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d02113",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b27dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo # to directly import the dataset from its repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b6510",
   "metadata": {},
   "source": [
    "## **Loading and Preprocessing the Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd4a1b",
   "metadata": {},
   "source": [
    "Before we use train the network, we import the dataset from its repository using the ```ucimlrepo``` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69074ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = fetch_ucirepo(id=17) # import the dataset from the ML repo\n",
    "\n",
    "# extract features and its values/targets\n",
    "X = breast_cancer.data.features\n",
    "y = breast_cancer.data.targets\n",
    "\n",
    "# combine into one DataFrame\n",
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebdd18",
   "metadata": {},
   "source": [
    "We then preprocess the dataset by standardizing the feature names and converting the diagnosis values from ```'M/B'``` to ```'1/0'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4378c3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "0    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
       "1    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
       "2    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
       "3    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
       "4    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1  fractal_dimension1  ...  texture3  \\\n",
       "0      0.3001          0.14710     0.2419             0.07871  ...     17.33   \n",
       "1      0.0869          0.07017     0.1812             0.05667  ...     23.41   \n",
       "2      0.1974          0.12790     0.2069             0.05999  ...     25.53   \n",
       "3      0.2414          0.10520     0.2597             0.09744  ...     26.50   \n",
       "4      0.1980          0.10430     0.1809             0.05883  ...     16.67   \n",
       "\n",
       "   perimeter3   area3  smoothness3  compactness3  concavity3  concave_points3  \\\n",
       "0      184.60  2019.0       0.1622        0.6656      0.7119           0.2654   \n",
       "1      158.80  1956.0       0.1238        0.1866      0.2416           0.1860   \n",
       "2      152.50  1709.0       0.1444        0.4245      0.4504           0.2430   \n",
       "3       98.87   567.7       0.2098        0.8663      0.6869           0.2575   \n",
       "4      152.20  1575.0       0.1374        0.2050      0.4000           0.1625   \n",
       "\n",
       "   symmetry3  fractal_dimension3  diagnosis  \n",
       "0     0.4601             0.11890          1  \n",
       "1     0.2750             0.08902          1  \n",
       "2     0.3613             0.08758          1  \n",
       "3     0.6638             0.17300          1  \n",
       "4     0.2364             0.07678          1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase 'diagnosis' column for standardization \n",
    "df.rename(columns={df.columns[-1]: 'diagnosis'}, inplace=True)\n",
    "\n",
    "# convert diagnosis values to binary (M=1, B=0)\n",
    "y = y['Diagnosis'].map({'M':1,'B':0})\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff1f02",
   "metadata": {},
   "source": [
    "\n",
    "## **Feature Selection (using Correlation) and Standardization**\n",
    "In this step, we identify the two features most correlated with the target ```diagnosis```. <br>We use the **Pearson correlation coefficient**, particularly panda's ```corr``` function to measures the linear relationship between two variables. \n",
    "\n",
    "A higher absolute correlation value (closer to 1 or -1) means that changes in the feature are strongly associated with changes in the target, making that feature more useful for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2b5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis          1.000000\n",
       "concave_points3    0.793566\n",
       "perimeter3         0.782914\n",
       "concave_points1    0.776614\n",
       "radius3            0.776454\n",
       "perimeter1         0.742636\n",
       "area3              0.733825\n",
       "radius1            0.730029\n",
       "area1              0.708984\n",
       "concavity1         0.696360\n",
       "Name: diagnosis, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr(method='pearson')['diagnosis'].abs().sort_values(ascending=False)\n",
    "corr.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e8482",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"font-size:12px\">*GeeksforGeeks. (2025, July 23). Pearson Correlation Coefficient. GeeksforGeeks. https://www.geeksforgeeks.org/maths/pearson-correlation-coefficient/*</span>\n",
    "<br><span style=\"font-size:12px\">*GeeksforGeeks. (2025b, July 11). Pandas DataFrame corr() Method. GeeksforGeeks. https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-corr/*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdd501",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<br><br>Since we're limited to using only 2 input features, we pick the top 2 most correlated features to ```diagnosis```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eecaf99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['concave_points3', 'perimeter3']\n"
     ]
    }
   ],
   "source": [
    "top_features = corr.index[1:3].tolist()\n",
    "\n",
    "# extract top 2 correlated features\n",
    "X_selected = X[top_features]\n",
    "\n",
    "print(\"Selected features:\", top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdea1e",
   "metadata": {},
   "source": [
    "The next step is to standardize teh features using the following formula:\n",
    "$$\n",
    "X'_j = (X_j - μ_j) / σ_j\n",
    "$$\n",
    "\n",
    "This helps gradient descent converge faster and prevents features with large scale dominating updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81574485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features  \n",
    "X_scaled = (X_selected - X_selected.mean()) / X_selected.std()\n",
    "X_np = X_scaled.values\n",
    "y_np = y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becab904",
   "metadata": {},
   "source": [
    "***\n",
    "## **Activation functions**\n",
    "\n",
    "Activation functions introduce **non-linearity** into the network, allowing it to learn complex patterns.\n",
    "In this notebook, we use ```ReLU (Rectified Linear Unit):``` and ```Sigmoid:``` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): \n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x): \n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x): \n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f023b85",
   "metadata": {},
   "source": [
    "***\n",
    "## **Core Neural Network Training Loop**\n",
    "\n",
    "### I. *Splitting the dataset*\n",
    "First and crucial step we take before training the network is to split the dataset into **80% training data** and **20% testing data**. <br>This prevents overfitting and checks how well the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "split = int(0.8 * len(X_np))\n",
    "X_train, X_test = X_np[:split], X_np[split:]\n",
    "y_train, y_test = y_np[:split], y_np[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac0fc74",
   "metadata": {},
   "source": [
    "### II. *Network Structure and Initialization*\n",
    "Before training, we define the architecture of the neural network and initialize its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aac478",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # ensures reproducibility (same random numbers each run).\n",
    "input_size, hidden_size, output_size = 2, 4, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecdbd61",
   "metadata": {},
   "source": [
    "We then initialize the **weights** and **biases** randomly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.1\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.1\n",
    "b2 = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b1aca",
   "metadata": {},
   "source": [
    "We also define constants that control how the training process behaves and create an empty list `losses = []` to store the loss per epoch, allowing us to visualize training progress later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, epochs = 0.5, 800\n",
    "\n",
    "losses = []  # store loss per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab93c7",
   "metadata": {},
   "source": [
    "### III. *Forward Propagation*\n",
    "\n",
    "The function defines the **forward pass** of the neural network, following a step-by-step process as defined by the code below. \n",
    "<br>This function returns a1 (hidden layer activation) and a2 (output layer activation or predicted probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6beec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return a1,a2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce62689",
   "metadata": {},
   "source": [
    "### III. *Backward Propagation*\n",
    "\n",
    "This function computes the gradient of the **loss** with respect to the output layer’s pre-activation ```( z_2 )```.\n",
    "<br>This gradient ```(d_z2)``` will be used to propagate the error backward through the network to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a57e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(y):\n",
    "    d_loss_a2 = -(y - a2)\n",
    "    d_a2_z2 = sigmoid_derivative(a2)\n",
    "    d_z2 = d_loss_a2 * d_a2_z2\n",
    "    return d_z2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
